import os
import json
import logging
import hashlib
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Set
from dynamic_category_manager import DynamicCategoryManager

logger = logging.getLogger(__name__)

class EnhancedFileManager:
    def __init__(self, base_path: str, file_format: str = ".md"):
        """í–¥ìƒëœ íŒŒì¼ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.base_path = Path(base_path)
        self.file_format = file_format
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ì •ì˜ (í•„ìš”í•  ë•Œë§Œ ìƒì„±)
        self.topics_dir = self.base_path / "Topics"
        self.daily_dir = self.base_path / "DailyEmails"
        
        # ì¤‘ë³µ ë°©ì§€ìš© ì¸ë±ìŠ¤ íŒŒì¼
        self.processed_index_file = self.base_path / "processed_index.json"
        self.processed_index = self._load_processed_index()
        
        # ë™ì  ì¹´í…Œê³ ë¦¬ ê´€ë¦¬ì
        self.category_manager = DynamicCategoryManager(str(self.base_path))
        
        logger.info(f"í–¥ìƒëœ íŒŒì¼ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ: {self.base_path}")
    
    def _load_processed_index(self) -> Dict:
        """ì²˜ë¦¬ëœ ë©”ì¼ ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            if self.processed_index_file.exists():
                with open(self.processed_index_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {}
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ëœ ë©”ì¼ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def _save_processed_index(self):
        """ì²˜ë¦¬ëœ ë©”ì¼ ì¸ë±ìŠ¤ ì €ì¥"""
        try:
            with open(self.processed_index_file, 'w', encoding='utf-8') as f:
                json.dump(self.processed_index, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ëœ ë©”ì¼ ì¸ë±ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _calculate_content_checksum(self, mail_data: Dict) -> str:
        """ë©”ì¼ ë‚´ìš© ì²´í¬ì„¬ ê³„ì‚°"""
        content = f"{mail_data.get('subject', '')}{mail_data.get('date', '')}{mail_data.get('sender', '')}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()[:16]
    
    def is_already_processed(self, mail_id: str, mail_data: Dict) -> bool:
        """ë©”ì¼ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ID + ë‚´ìš© ì²´í¬ì„¬ ì´ì¤‘ ê²€ì¦)"""
        if mail_id not in self.processed_index:
            return False
        
        # ë‚´ìš© ì²´í¬ì„¬ í™•ì¸ìœ¼ë¡œ ì´ì¤‘ ê²€ì¦
        current_checksum = self._calculate_content_checksum(mail_data)
        stored_checksum = self.processed_index[mail_id].get('checksum', '')
        
        if current_checksum != stored_checksum:
            logger.warning(f"ë©”ì¼ IDëŠ” ë™ì¼í•˜ì§€ë§Œ ë‚´ìš©ì´ ë‹¤ë¦„: {mail_id}")
            return False
        
        logger.debug(f"ì´ë¯¸ ì²˜ë¦¬ëœ ë©”ì¼: {mail_id} ({self.processed_index[mail_id]['date']})")
        return True
    
    def save_mail_enhanced(self, mail_data: Dict, classification: Dict, mail_id: str) -> Dict:
        """í–¥ìƒëœ ë©”ì¼ ì €ì¥ (ì£¼ì œë³„ + ë‚ ì§œë³„)"""
        try:
            # ì¤‘ë³µ í™•ì¸
            if self.is_already_processed(mail_id, mail_data):
                return {
                    "status": "skipped", 
                    "reason": "already_processed",
                    "mail_id": mail_id
                }
            
            # ë™ì  ì¹´í…Œê³ ë¦¬ ì¶”ì²œ ë°›ê¸°
            recommendation = self.category_manager.get_category_recommendation(mail_data)
            final_category = recommendation["suggested_category"]
            
            # ì‚¬ìš©ì ë¶„ë¥˜ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if classification.get('category') and classification['category'] != 'ê¸°íƒ€':
                final_category = classification['category']
            
            # ì¹´í…Œê³ ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸
            self.category_manager.update_category_stats(final_category, mail_data)
            
            # ì‹¤ì œë¡œ íŒŒì¼ì„ ì €ì¥í•  ë•Œë§Œ í´ë” ìƒì„±
            self.topics_dir.mkdir(parents=True, exist_ok=True)
            self.daily_dir.mkdir(parents=True, exist_ok=True)
            
            current_time = datetime.now()
            date_str = current_time.strftime("%Y-%m-%d")
            time_str = current_time.strftime("%H:%M")
            
            result = {
                "status": "success",
                "mail_id": mail_id,
                "category": final_category,
                "files_created": [],
                "recommendation": recommendation
            }
            
            # 1. ì£¼ì œë³„ íŒŒì¼ì— ì €ì¥ (ìµœì‹  ë‚´ìš© ìœ„ë¡œ)
            topic_file_path = self._save_to_topic_file(
                final_category, mail_data, classification, date_str, time_str
            )
            result["files_created"].append(str(topic_file_path))
            
            # 2. ë‚ ì§œë³„ íŒŒì¼ì— ì €ì¥
            daily_file_path = self._save_to_daily_file(
                mail_data, classification, final_category, date_str, time_str
            )
            result["files_created"].append(str(daily_file_path))
            
            # 3. ì²˜ë¦¬ëœ ë©”ì¼ ì¸ë±ìŠ¤ì— ì¶”ê°€
            self._add_to_processed_index(mail_id, mail_data, final_category)
            
            # 4. ì¹´í…Œê³ ë¦¬ ì¬í¸ í•„ìš”ì„± í™•ì¸ (100ê°œë§ˆë‹¤)
            total_processed = len(self.processed_index)
            if total_processed > 0 and total_processed % 100 == 0:
                result["reorganization_check"] = self._check_reorganization_needs()
            
            logger.info(f"ë©”ì¼ ì €ì¥ ì™„ë£Œ: {mail_id} â†’ {final_category}")
            return result
            
        except Exception as e:
            logger.error(f"ë©”ì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "mail_id": mail_id,
                "error": str(e)
            }
    
    def _save_to_topic_file(self, category: str, mail_data: Dict, classification: Dict, 
                           date_str: str, time_str: str) -> Path:
        """ì£¼ì œë³„ íŒŒì¼ì— ì €ì¥ (ìµœì‹  ë‚´ìš© ìœ„ë¡œ)"""
        filename = f"{self._sanitize_filename(category)}{self.file_format}"
        filepath = self.topics_dir / filename
        
        # ìƒˆ ë©”ì¼ ë‚´ìš© ìƒì„±
        new_content = self._create_topic_entry(mail_data, classification, date_str, time_str)
        
        if filepath.exists():
            # ê¸°ì¡´ íŒŒì¼ì— ìµœì‹  ë‚´ìš©ì„ ìœ„ì— ì¶”ê°€
            with open(filepath, 'r', encoding='utf-8') as f:
                existing_content = f.read()
            
            # í—¤ë”ì™€ ë³¸ë¬¸ ë¶„ë¦¬
            lines = existing_content.split('\n')
            header_end = 0
            for i, line in enumerate(lines):
                if line.strip() == "---" and i > 3:  # ì²« ë²ˆì§¸ êµ¬ë¶„ì„  ì°¾ê¸°
                    header_end = i + 1
                    break
            
            if header_end > 0:
                header = '\n'.join(lines[:header_end])
                body = '\n'.join(lines[header_end:])
                content = header + '\n' + new_content + '\n' + body
            else:
                content = new_content + '\n\n' + existing_content
        else:
            # ìƒˆ íŒŒì¼ ìƒì„±
            header = f"# {category}\n\nìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n---\n\n"
            content = header + new_content
        
        # íŒŒì¼ ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return filepath
    
    def _save_to_daily_file(self, mail_data: Dict, classification: Dict, category: str,
                           date_str: str, time_str: str) -> Path:
        """ë‚ ì§œë³„ íŒŒì¼ì— ì£¼ì œë³„ë¡œ ì •ë¦¬í•´ì„œ ì €ì¥ (í†µê³„ ì—†ì´)"""
        filename = f"{date_str}{self.file_format}"
        filepath = self.daily_dir / filename
        
        # ìƒˆ ë©”ì¼ ì—”íŠ¸ë¦¬ ìƒì„±
        new_entry = f"### {time_str} - {mail_data.get('subject', 'ì œëª© ì—†ìŒ')}\n"
        new_entry += f"**ìš”ì•½**: {classification.get('summary', 'ìš”ì•½ ì—†ìŒ')}\n\n"
        
        if classification.get('action_required'):
            new_entry += "âš ï¸ **ì¡°ì¹˜ í•„ìš”**\n\n"
        
        new_entry += "---\n\n"
        
        if filepath.exists():
            # ê¸°ì¡´ íŒŒì¼ ì½ê¸°
            with open(filepath, 'r', encoding='utf-8') as f:
                existing_content = f.read()
            
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ ì°¾ì•„ì„œ ì¶”ê°€
            content = self._add_to_category_section(existing_content, category, new_entry, date_str)
        else:
            # ìƒˆ íŒŒì¼ ìƒì„±
            header = f"# {date_str} ë©”ì¼ ìš”ì•½\n\n"
            content = header + f"## ğŸ“§ {category}\n\n" + new_entry
        
        # íŒŒì¼ ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return filepath
    
    def _add_to_category_section(self, existing_content: str, category: str, new_entry: str, date_str: str) -> str:
        """ê¸°ì¡´ ë‚´ìš©ì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ì„ ì°¾ì•„ì„œ ìƒˆ ì—”íŠ¸ë¦¬ ì¶”ê°€"""
        lines = existing_content.split('\n')
        category_section = f"## ğŸ“§ {category}"
        
        # ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ì´ ìˆëŠ”ì§€ ì°¾ê¸°
        category_index = -1
        for i, line in enumerate(lines):
            if line == category_section:
                category_index = i
                break
        
        if category_index >= 0:
            # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ì— ì¶”ê°€ (ì„¹ì…˜ ë°”ë¡œ ë‹¤ìŒì—)
            next_section_index = len(lines)
            for i in range(category_index + 1, len(lines)):
                if lines[i].startswith("## ğŸ“§"):
                    next_section_index = i
                    break
            
            # ìƒˆ ì—”íŠ¸ë¦¬ë¥¼ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ ëì— ì¶”ê°€
            lines.insert(next_section_index, new_entry.rstrip())
            return '\n'.join(lines)
        else:
            # ìƒˆ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ ìƒì„± (ë§¨ ëì— ì¶”ê°€)
            return existing_content.rstrip() + f"\n\n{category_section}\n\n{new_entry}"
    
    def _create_topic_entry(self, mail_data: Dict, classification: Dict, 
                           date_str: str, time_str: str) -> str:
        """ì£¼ì œë³„ íŒŒì¼ ì—”íŠ¸ë¦¬ ìƒì„±"""
        content = []
        
        content.append(f"## ğŸ“… {date_str} {time_str}")
        content.append(f"### {mail_data.get('subject', 'ì œëª© ì—†ìŒ')}")
        content.append("")
        
        if classification.get('action_required'):
            content.append("âš ï¸ **ì¡°ì¹˜ í•„ìš”**")
            content.append("")
        
        content.append("**ìš”ì•½:**")
        content.append(classification.get('summary', 'ìš”ì•½ ì—†ìŒ'))
        content.append("")
        
        # í‚¤ì›Œë“œ/íƒœê·¸
        if classification.get('key_concepts') or classification.get('tags'):
            all_concepts = []
            if classification.get('key_concepts'):
                all_concepts.extend(classification['key_concepts'])
            if classification.get('tags'):
                all_concepts.extend(classification['tags'])
            
            unique_concepts = list(dict.fromkeys(all_concepts))
            if unique_concepts:
                concept_links = [f"[[{concept}]]" for concept in unique_concepts if concept.strip()]
                content.append("**ê´€ë ¨ ê°œë…:** " + " Â· ".join(concept_links[:5]))
                content.append("")
        
        content.append("---")
        content.append("")
        
        return '\n'.join(content)
    
    def _add_to_processed_index(self, mail_id: str, mail_data: Dict, category: str):
        """ì²˜ë¦¬ëœ ë©”ì¼ ì¸ë±ìŠ¤ì— ì¶”ê°€"""
        self.processed_index[mail_id] = {
            "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "subject": mail_data.get('subject', '')[:100],  # 100ìë¡œ ì œí•œ
            "category": category,
            "checksum": self._calculate_content_checksum(mail_data)
        }
        self._save_processed_index()
    
    def _check_reorganization_needs(self):
        """ì¹´í…Œê³ ë¦¬ ì¬í¸ í•„ìš”ì„± í™•ì¸"""
        try:
            reorganization_plan = self.category_manager.analyze_reorganization_needs()
            
            if reorganization_plan["needs_reorganization"]:
                logger.info(f"ì¹´í…Œê³ ë¦¬ ì¬í¸ í•„ìš” ê°ì§€:")
                logger.info(f"- ì €ë¹ˆë„ ì¹´í…Œê³ ë¦¬: {len(reorganization_plan['low_frequency_categories'])}ê°œ")
                logger.info(f"- ë³‘í•© ì œì•ˆ: {len(reorganization_plan['merge_suggestions'])}ê°œ")
                logger.info(f"- ì´ ì¹´í…Œê³ ë¦¬ ìˆ˜: {reorganization_plan['total_categories']}ê°œ")
                
                # ìë™ ì¬í¸ ì‹¤í–‰ (í–¥í›„ ì‚¬ìš©ì í™•ì¸ ê¸°ëŠ¥ ì¶”ê°€ ì˜ˆì •)
                if len(reorganization_plan['low_frequency_categories']) > 0:
                    logger.info("ìë™ ì¹´í…Œê³ ë¦¬ ì¬í¸ ì‹¤í–‰...")
                    result = self.category_manager.execute_reorganization(reorganization_plan, True)
                    if result["status"] == "success":
                        logger.info(f"ì¹´í…Œê³ ë¦¬ ì¬í¸ ì™„ë£Œ: {len(result['actions_taken'])}ê°œ ì‘ì—… ìˆ˜í–‰")
                        self._reorganize_files(result)
                        return {
                            "reorganized": True,
                            "actions": result['actions_taken'],
                            "plan": reorganization_plan
                        }
                
                return {
                    "reorganized": False,
                    "needs_reorganization": True,
                    "plan": reorganization_plan
                }
            
            return {
                "reorganized": False,
                "needs_reorganization": False
            }
        
        except Exception as e:
            logger.error(f"ì¹´í…Œê³ ë¦¬ ì¬í¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {"reorganized": False, "error": str(e)}
    
    def _reorganize_files(self, reorganization_result: Dict):
        """íŒŒì¼ ì¬í¸ì„±"""
        try:
            # ì œê±°ëœ ì¹´í…Œê³ ë¦¬ íŒŒì¼ë“¤ì„ ê¸°íƒ€ë¡œ ë³‘í•©
            for removed_category in reorganization_result.get("categories_removed", []):
                old_file = self.topics_dir / f"{self._sanitize_filename(removed_category)}{self.file_format}"
                if old_file.exists():
                    misc_file = self.topics_dir / f"ê¸°íƒ€{self.file_format}"
                    self._merge_topic_files(old_file, misc_file, "ê¸°íƒ€")
                    old_file.unlink()  # ì›ë³¸ íŒŒì¼ ì‚­ì œ
                    logger.info(f"íŒŒì¼ ì¬í¸: {removed_category} â†’ ê¸°íƒ€")
            
            # ë³‘í•©ëœ ì¹´í…Œê³ ë¦¬ íŒŒì¼ë“¤ ì²˜ë¦¬
            for merge_info in reorganization_result.get("categories_merged", []):
                from_categories = merge_info["from"]
                to_category = merge_info["to"]
                
                # ìƒˆ íŒŒì¼ë¡œ ë³‘í•©
                new_file = self.topics_dir / f"{self._sanitize_filename(to_category)}{self.file_format}"
                
                for old_category in from_categories:
                    old_file = self.topics_dir / f"{self._sanitize_filename(old_category)}{self.file_format}"
                    if old_file.exists():
                        self._merge_topic_files(old_file, new_file, to_category)
                        old_file.unlink()  # ì›ë³¸ íŒŒì¼ ì‚­ì œ
                        logger.info(f"íŒŒì¼ ë³‘í•©: {old_category} â†’ {to_category}")
        
        except Exception as e:
            logger.error(f"íŒŒì¼ ì¬í¸ì„± ì‹¤íŒ¨: {e}")
    
    def _merge_topic_files(self, source_file: Path, target_file: Path, target_category: str):
        """ì£¼ì œ íŒŒì¼ë“¤ ë³‘í•©"""
        try:
            # ì›ë³¸ íŒŒì¼ ë‚´ìš© ì½ê¸°
            with open(source_file, 'r', encoding='utf-8') as f:
                source_content = f.read()
            
            # í—¤ë” ì œê±° (ì²« ë²ˆì§¸ --- ê¹Œì§€)
            lines = source_content.split('\n')
            content_start = 0
            for i, line in enumerate(lines):
                if line.strip() == "---":
                    content_start = i + 1
                    break
            
            source_body = '\n'.join(lines[content_start:]).strip()
            
            if target_file.exists():
                # ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€
                with open(target_file, 'r', encoding='utf-8') as f:
                    target_content = f.read()
                
                # ê¸°ì¡´ ë‚´ìš© ëì— ìƒˆ ë‚´ìš© ì¶”ê°€
                merged_content = target_content.rstrip() + '\n\n' + source_body
            else:
                # ìƒˆ íŒŒì¼ ìƒì„±
                header = f"# {target_category}\n\nìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n---\n\n"
                merged_content = header + source_body
            
            # ë³‘í•©ëœ ë‚´ìš© ì €ì¥
            with open(target_file, 'w', encoding='utf-8') as f:
                f.write(merged_content)
        
        except Exception as e:
            logger.error(f"íŒŒì¼ ë³‘í•© ì‹¤íŒ¨: {e}")
    
    def _sanitize_filename(self, text: str) -> str:
        """íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ìë¡œ ë³€í™˜"""
        import re
        text = re.sub(r'[<>:"/\\|?*]', '', text)
        text = text.strip()
        return text or "ê¸°íƒ€"
    
    def get_processing_statistics(self) -> Dict:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        total_processed = len(self.processed_index)
        if total_processed == 0:
            return {"total_processed": 0, "categories": {}, "recent_activity": []}
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_stats = {}
        recent_activity = []
        
        for mail_id, info in self.processed_index.items():
            category = info["category"]
            if category not in category_stats:
                category_stats[category] = 0
            category_stats[category] += 1
            
            # ìµœê·¼ 5ê°œ í™œë™
            if len(recent_activity) < 5:
                recent_activity.append({
                    "date": info["date"],
                    "subject": info["subject"],
                    "category": category
                })
        
        # ì¹´í…Œê³ ë¦¬ í˜„í™©
        category_overview = self.category_manager.get_category_overview()
        
        return {
            "total_processed": total_processed,
            "categories": category_stats,
            "recent_activity": sorted(recent_activity, key=lambda x: x["date"], reverse=True),
            "category_overview": category_overview,
            "files_structure": {
                "topics_dir": str(self.topics_dir),
                "daily_dir": str(self.daily_dir),
                "topic_files": len(list(self.topics_dir.glob("*" + self.file_format))),
                "daily_files": len(list(self.daily_dir.glob("*" + self.file_format)))
            }
        }